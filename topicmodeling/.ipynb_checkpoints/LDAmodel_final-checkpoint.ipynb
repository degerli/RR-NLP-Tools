{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Topic Modeling\n",
    "---\n",
    "\n",
    "Preforming LDA topic modeling with R&R terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjz1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "import operator\n",
    "from operator import methodcaller\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import math\n",
    "import itertools\n",
    "import sqlite3\n",
    "import copy\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Read in the output from the R&R program. Tokenize the terms and remove blacklisted tokens. Build a corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to blacklisted tokens\n",
    "blacklist = [t.strip() for t in next(csv.reader(open(\"tools\\\\blacklist.csv\", 'r')))]\n",
    "\n",
    "# levels of R&R terms considered\n",
    "levels = [1, 2, 3]\n",
    "\n",
    "# format [term, orig, sentence, docID]\n",
    "inPath = \"raw.csv\"\n",
    "inFile = open(inPath, 'r')\n",
    "inReader = csv.reader(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docTokens = dict()\n",
    "\n",
    "# ignore headers\n",
    "next(inReader)\n",
    "\n",
    "for inRow in inReader:\n",
    "    term = inRow[0]\n",
    "    sentence = inRow[2]\n",
    "    docID = inRow[3]\n",
    "    \n",
    "    # find acceptable tokens only\n",
    "    token = \"_\".join([t for t in term.split(\":\") if re.match(r'[^\\W\\d]*$', t) and not t in blacklist])\n",
    "\n",
    "    # calculate new term level\n",
    "    level = token.count(\"_\")\n",
    "\n",
    "    # if acceptable, add to dictionary\n",
    "    if level in levels and not token in blacklist and len(token) > 0:\n",
    "        if docID in docTokens:\n",
    "            docTokens[docID] += [token]\n",
    "        else:\n",
    "            docTokens[docID] = [token]\n",
    "\n",
    "# compile all IDs and texts\n",
    "docIDs = list(docTokens.keys())\n",
    "texts = list(docTokens.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dictionary: 16391 terms\n",
      "Filtered dictionary: 16386 terms\n",
      "crystal_structure\n",
      "hydrogen_bond\n",
      "dihedral_angle\n",
      "n_h\n",
      "c_h\n"
     ]
    }
   ],
   "source": [
    "# build a dictionary for the text\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(\"Raw dictionary: \" + str(len(dictionary)) + \" terms\")\n",
    "\n",
    "# filter out terms that appear in fewer that LOW docs or greater than HIGH percent of docs and use KEEP terms\n",
    "LOW = 1\n",
    "HIGH = 0.14\n",
    "KEEP = 20000\n",
    "\n",
    "old_dict = copy.copy(dictionary)\n",
    "\n",
    "dictionary.filter_extremes(no_below = LOW, no_above = HIGH, keep_n = KEEP)\n",
    "print(\"Filtered dictionary: \" + str(len(dictionary)) + \" terms\")\n",
    "\n",
    "for word in old_dict.values():\n",
    "    if not word in dictionary.values():\n",
    "        print(word)\n",
    "\n",
    "# convert the text to a corpus with the dictionary\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# perform TF-IDF on the corpus\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Standard LDA modeling. Toggle the number of topics, passes, and iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(corpus, numtop, passes, iterations):\n",
    "\n",
    "    # run LDA with four cores\n",
    "    model = gensim.models.LdaMulticore(corpus, \n",
    "                                       num_topics=numtop, \n",
    "                                       id2word=dictionary, \n",
    "                                       passes=passes, \n",
    "                                       workers=4,\n",
    "                                       iterations=iterations)\n",
    "\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a set of trials and write results to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder to write databases to\n",
    "STEM = \"databases\\\\\"\n",
    "\n",
    "# set range of passes and topics to test\n",
    "passes = []\n",
    "topics = []\n",
    "\n",
    "for p in passes:\n",
    "    for t in topics:\n",
    "        \n",
    "        # create database\n",
    "        con = sqlite3.connect(STEM + \"topics_p\" + str(p+\"_t\"+str(t)+\".db\"))\n",
    "        cur = con.cursor()\n",
    "        \n",
    "        # train model\n",
    "        print(\"Training LDA...\")\n",
    "        model = model(corpus, p, t, 500)           \n",
    "        print(\"Done.\")\n",
    "                              \n",
    "        # write the topic-terms table\n",
    "        print(\"Writing topics to terms...\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS TERMS\n",
    "                (topic INT,\n",
    "                term TEXT,\n",
    "                prob FLOAT)\n",
    "        \"\"\")\n",
    "\n",
    "        for i in range(lda_model.num_topics):\n",
    "            topics = lda_model.show_topic(i, topn = 20)\n",
    "            for t in topics:\n",
    "                cur.execute(\"INSERT INTO TERMS (topic, term, prob) VALUES (?, ?, ?)\", [i+1, t[0], t[1]])\n",
    "\n",
    "        print(\"Done.\")\n",
    "                              \n",
    "        # write the doc-topics table\n",
    "        print(\"Writing doc to topics...\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS DOCS\n",
    "                (doc TEXT,\n",
    "                topic INT,\n",
    "                prob FLOAT)\n",
    "        \"\"\")\n",
    "\n",
    "        for ID in docIDs:\n",
    "\n",
    "            doc = docTokens[ID]\n",
    "            store = list(model.get_document_topics(dictionary.doc2bow(doc)))\n",
    "\n",
    "            for pair in store:\n",
    "\n",
    "                cur.execute(\"INSERT INTO DOCS (doc, topic, prob) VALUES (?, ?, ?)\", [docID, pair[0], pair[1]])\n",
    "\n",
    "        print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cyclical tests, with a lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic(minp, rat, p, its):\n",
    "    \n",
    "    done = False\n",
    "    newcorpus = copy.copy(corpus)\n",
    "    newIDs = docIDs.copy()\n",
    "    totalTopics = 0\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        t = math.ceil(len(newcorpus) * rat)\n",
    "        totalTopics += t\n",
    "        \n",
    "        newmodel = model(newcorpus, t, p, its)\n",
    "        \n",
    "        print(newmodel.print_topics())\n",
    "        \n",
    "        badIDs = list()\n",
    "        \n",
    "        for ID in newIDs:\n",
    "            doc = docTokens[ID]\n",
    "            store = list(newmodel.get_document_topics(dictionary.doc2bow(doc), minimum_probability = minp))\n",
    "            \n",
    "            if len(store) == 0:\n",
    "                badIDs.append(ID)\n",
    "        \n",
    "        if len(badIDs) == 0:\n",
    "            done = True\n",
    "        else:\n",
    "            newIDs = badIDs\n",
    "            newcorpus = [dictionary.doc2bow(docTokens[ID]) for ID in newIDs]\n",
    "            print(len(badIDs))\n",
    "            \n",
    "    print(\"Total topics: \" + str(totalTopics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.002*\"n_hydrogen_bond\" + 0.001*\"n_hydrogen\" + 0.001*\"n_o\" + 0.001*\"pi_interaction\" + 0.001*\"molecular_conformation\" + 0.001*\"n_o_h\" + 0.001*\"ring_system\" + 0.001*\"weak_c_h\" + 0.001*\"intermolecular_n_h\" + 0.001*\"intramolecular_o_h\"'), (1, '0.001*\"weak_intermolecular_c_h\" + 0.001*\"n_atom\" + 0.001*\"intermolecular_n_h\" + 0.001*\"o_o_h\" + 0.001*\"dimensional_network\" + 0.001*\"chair_conformation\" + 0.001*\"fuse_ring\" + 0.001*\"deg_dihedral_angle\" + 0.001*\"n_hydrogen_bond\" + 0.001*\"intermolecular_c_h\"'), (2, '0.001*\"intermolecular_n_h\" + 0.001*\"o_o_h\" + 0.001*\"n_hydrogen_bond\" + 0.001*\"n_atom\" + 0.001*\"site_symmetry\" + 0.001*\"chloride_reaction_product\" + 0.001*\"asymmetric_unit_molecule\" + 0.001*\"benzene_ring\" + 0.000*\"hydrogen_bond_interaction\" + 0.000*\"dimensional_structure\"'), (3, '0.001*\"n_o_h\" + 0.001*\"n_o\" + 0.001*\"intermolecular_n_h\" + 0.001*\"benzene_ring\" + 0.001*\"n_hydrogen_bond\" + 0.001*\"supramolecular_network\" + 0.001*\"c_o\" + 0.001*\"intermolecular_c_h\" + 0.001*\"b_axis_chain\" + 0.001*\"octahedral_geometry\"'), (4, '0.001*\"intermolecular_n_h\" + 0.001*\"weak_c_h\" + 0.001*\"crystallographic_inversion_symmetry\" + 0.001*\"space_group\" + 0.001*\"schiff_base\" + 0.001*\"crystal_pack\" + 0.001*\"square_planar_geometry\" + 0.001*\"benzene_phenyl\" + 0.001*\"benzene_phenyl_ring\" + 0.001*\"dimensional_network\"'), (5, '0.001*\"c_n_h\" + 0.001*\"crystal_pack\" + 0.001*\"intermolecular_c_h\" + 0.001*\"n_atom\" + 0.001*\"n_n_h\" + 0.001*\"asymmetric_unit_molecule\" + 0.001*\"benzene_ring\" + 0.001*\"c_n\" + 0.001*\"weak_c_h\" + 0.001*\"base_ligand\"'), (6, '0.001*\"cl_interaction\" + 0.001*\"weak_c_h\" + 0.001*\"twofold_rotation_axis\" + 0.001*\"mononuclear_complex\" + 0.001*\"rotation_axis\" + 0.001*\"cl_hydrogen_bond\" + 0.001*\"structurally_characterize_phosphonate_sulfonylhydrazone\" + 0.001*\"prismatic_geometry\" + 0.001*\"space_group\" + 0.001*\"benzene_ring\"'), (7, '0.001*\"weak_c_h\" + 0.001*\"c_bond\" + 0.001*\"complex_cation\" + 0.001*\"hydrogen_bond_centrosymmetric_dimer\" + 0.001*\"intermolecular_n_h\" + 0.001*\"improve_precision\" + 0.001*\"molecule_crystallographic_symmetry_possess\" + 0.001*\"weak_c\" + 0.001*\"pi_pi\" + 0.000*\"hypersphere_pack\"'), (8, '0.001*\"intermolecular_n_h\" + 0.001*\"weak_c_h\" + 0.001*\"intermolecular_o_h\" + 0.001*\"aromatic_pi\" + 0.001*\"phenyl_ring\" + 0.001*\"n_n_h\" + 0.001*\"benzene_ring\" + 0.001*\"n_atom\" + 0.001*\"ewald_prize_nomination\" + 0.001*\"isovanillin_group\"'), (9, '0.001*\"benzene_ring\" + 0.001*\"pi_interaction\" + 0.001*\"weak_c_h\" + 0.001*\"adjacent_molecule\" + 0.001*\"n_n_h\" + 0.001*\"intermolecular_c_h\" + 0.001*\"space_group\" + 0.001*\"aromatic_ring\" + 0.001*\"article_citation\" + 0.001*\"attach_benzene_ring\"'), (10, '0.001*\"sn_atom\" + 0.001*\"water_molecule\" + 0.001*\"space_group\" + 0.001*\"asymmetric_unit_molecule\" + 0.001*\"mononuclear_complex\" + 0.001*\"pi_interaction\" + 0.001*\"benzene_ring\" + 0.001*\"molecular_structure\" + 0.001*\"n_hydrogen_bond\" + 0.001*\"single_crystal\"'), (11, '0.001*\"pi_interaction\" + 0.001*\"weak_c_h\" + 0.001*\"n_atom\" + 0.001*\"centroid_distance\" + 0.001*\"mean_plane\" + 0.001*\"intermolecular_n_h\" + 0.001*\"polymeric_chain\" + 0.001*\"organometallic_complex\" + 0.001*\"room_temperature\" + 0.000*\"storage_ring\"'), (12, '0.001*\"weak_intermolecular_c_h\" + 0.001*\"membered_ring\" + 0.001*\"intermolecular_c_h\" + 0.001*\"envelope_conformation\" + 0.001*\"dihedral_angle_deg\" + 0.001*\"o_interaction\" + 0.001*\"benzene_ring\" + 0.001*\"intermolecular_n_h\" + 0.001*\"pi_interaction\" + 0.001*\"pyrrolidine_ring\"')]\n",
      "119\n",
      "[(0, '0.001*\"c_n_h\" + 0.001*\"c_n\" + 0.001*\"intermolecular_o_h\" + 0.000*\"angle_normal_bond_length\" + 0.000*\"intermolecular_hydrogen_bond\" + 0.000*\"water_molecule\" + 0.000*\"stack_interaction\" + 0.000*\"intramolecular_c_h\" + 0.000*\"twofold_rotation_axis\" + 0.000*\"rotation_axis\"'), (1, '0.004*\"n_hydrogen_bond\" + 0.003*\"intermolecular_n_h\" + 0.003*\"n_hydrogen\" + 0.003*\"benzene_ring\" + 0.002*\"pi_interaction\" + 0.002*\"weak_c_h\" + 0.001*\"intermolecular_c_h\" + 0.001*\"n_o\" + 0.001*\"independent_molecule\" + 0.001*\"n_atom\"')]\n",
      "8\n",
      "[(0, '0.000*\"c_n_h\" + 0.000*\"intermolecular_n_h\" + 0.000*\"strong_pi\" + 0.000*\"c_n\" + 0.000*\"maximum_deviation\" + 0.000*\"intermolecular_c_h\" + 0.000*\"pi_interaction\" + 0.000*\"site_symmetry_cdii_atom\" + 0.000*\"aring_centroid_centroid_distance\" + 0.000*\"n_n\"')]\n",
      "Total topics: 16\n"
     ]
    }
   ],
   "source": [
    "cyclic(0.8, 0.01, 100, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x0000020BEED768D0>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence Testing\n",
    "\n",
    "Test a range for the ideal number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = range(1, 21)\n",
    "passes = 5\n",
    "iterations = 500\n",
    "\n",
    "model_list = list()\n",
    "coherence_values = list()\n",
    "\n",
    "for topicnum in topics:\n",
    "\n",
    "    model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=topicnum, id2word=dictionary, passes=passes, workers =4, iterations=iterations)\n",
    "    model_list.append(model)\n",
    "    \n",
    "    coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "\n",
    "plt.plot(topics, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
