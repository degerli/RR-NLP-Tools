{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "---\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjz1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "from operator import methodcaller\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-ca56980ef058>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-ca56980ef058>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    and t not in blacklist\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "blacklist = [t.strip() for t in next(csv.reader(open(\"blacklist.csv\", 'r')))]\n",
    "\n",
    "inPath = \"input.csv\"\n",
    "outPath = \"out.csv\"\n",
    "wordBound = 10\n",
    "charBound = 70\n",
    "\n",
    "inFile = open(inPath, 'r')\n",
    "inReader = csv.reader(inFile)\n",
    "\n",
    "outFile = open(outPath, 'w')\n",
    "outWriter = csv.writer(outFile)\n",
    "\n",
    "\n",
    "docTokens = dict()\n",
    "\n",
    "\n",
    "next(inReader)\n",
    "for inRow in inReader:\n",
    "\n",
    "    charDist = int(inRow[0])\n",
    "    wordDist = int(inRow[1])\n",
    "\n",
    "    if wordDist < wordBound and charDist < charBound:\n",
    "\n",
    "        #predTerm, subTerm, objTerm = map(methodcaller(\"split\", \":\"), inRow[2:5])\n",
    "        #allTerms = predTerm + subTerm + objTerm\n",
    "\n",
    "        subTerm, objTerm = map(methodcaller(\"split\", \":\"), inRow[3:5])\n",
    "        and t not in blacklist \n",
    "        sub = \"_\".join([t for t in subTerm if re.match(r'[^\\W\\d]*$', t) and not t in blacklist])\n",
    "        obj = \"_\".join([t for t in subTerm if re.match(r'[^\\W\\d]*$', t) and not t in blacklist])\n",
    "        \n",
    "        tokens = list()\n",
    "        if not sub in blacklist and not obj in blacklist and len(sub) > 0 and len(obj) > 0:\n",
    "            tokens = [sub, obj]\n",
    "\n",
    "            docID = inRow[5]\n",
    "\n",
    "            if docID in docTokens:\n",
    "                docTokens[docID] += tokens\n",
    "            else:\n",
    "                docTokens[docID] = tokens\n",
    "\n",
    "data = list(docTokens.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-865f2059623b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data)\n",
    "texts = data\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       update_every=1,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       alpha='auto',\n",
    "                                       per_word_topics=True)\n",
    "\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjz1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Jul/2019 14:41:14] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/Jul/2019 14:41:14] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/Jul/2019 14:41:14] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/Jul/2019 14:41:14] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.show(vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
