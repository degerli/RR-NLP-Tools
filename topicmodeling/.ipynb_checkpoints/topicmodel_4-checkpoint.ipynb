{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjz1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "import operator\n",
    "from operator import methodcaller\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sci-kit\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import feature_extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [t.strip() for t in next(csv.reader(open(\"tools\\\\blacklist.csv\", 'r')))]\n",
    "levels = [1, 2, 3]\n",
    "\n",
    "# format [term, orig, sentence, docID]\n",
    "inPath = \"raw.csv\"\n",
    "\n",
    "inFile = open(inPath, 'r')\n",
    "inReader = csv.reader(inFile)\n",
    "\n",
    "docTokens = dict()\n",
    "\n",
    "# ignore headers\n",
    "next(inReader)\n",
    "\n",
    "for inRow in inReader:\n",
    "    \n",
    "    term = inRow[0]\n",
    "    sentence = inRow[2]\n",
    "    docID = inRow[3]\n",
    "    \n",
    "    # find acceptable tokens only\n",
    "    token = \"_\".join([t for t in term.split(\":\") if re.match(r'[^\\W\\d]*$', t) and not t in blacklist])\n",
    "    \n",
    "    # calculate new term level\n",
    "    level = token.count(\"_\")\n",
    "    \n",
    "    # if acceptable, add to dictionary\n",
    "    if level in levels and not token in blacklist and len(token) > 0:\n",
    "        if docID in docTokens:\n",
    "            docTokens[docID] += [token]\n",
    "        else:\n",
    "            docTokens[docID] = [token]\n",
    "                        \n",
    "docIDs = list(docTokens.keys())\n",
    "texts = list(docTokens.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16391\n",
      "825\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.2, keep_n=10000)\n",
    "print(len(dictionary))\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.031*\"structure_factor\" + 0.025*\"x_ray\" + 0.024*\"room_temperature\" + 0.023*\"datum_collection\" + 0.017*\"bragg_reflection\" + 0.017*\"diffraction_datum\" + 0.016*\"x_ray_diffraction\" + 0.016*\"cu_atom\" + 0.015*\"coordination_geometry\" + 0.014*\"square_planar\"\n",
      "\n",
      "Topic: 1 Word: 0.026*\"n_o\" + 0.026*\"centroid_distance\" + 0.024*\"n_o_h\" + 0.024*\"o_h\" + 0.024*\"pi_pi\" + 0.019*\"water_molecule\" + 0.018*\"centroid_centroid_distance\" + 0.018*\"dimensional_network\" + 0.015*\"square_pyramidal\" + 0.014*\"o_hydrogen_bond\"\n",
      "\n",
      "Topic: 2 Word: 0.057*\"single_crystal\" + 0.047*\"x_ray_diffraction\" + 0.032*\"x_ray\" + 0.028*\"x_ray_diffraction_datum\" + 0.026*\"octahedral_coordination\" + 0.018*\"octahedral_coordination_geometry\" + 0.018*\"solid_state\" + 0.017*\"molecular_structure\" + 0.017*\"distort_octahedral_coordination_geometry\" + 0.016*\"da_minus\"\n",
      "\n",
      "Topic: 3 Word: 0.049*\"n_h\" + 0.041*\"intermolecular_n_h\" + 0.035*\"n_hydrogen_bond\" + 0.034*\"o_hydrogen_bond\" + 0.028*\"o_h\" + 0.024*\"n_hydrogen\" + 0.024*\"asymmetric_unit\" + 0.019*\"pi_interaction\" + 0.019*\"dihedral_angle\" + 0.015*\"o_atom\"\n",
      "\n",
      "Topic: 4 Word: 0.025*\"independent_molecule\" + 0.024*\"n_hydrogen_bond\" + 0.019*\"tetrahedral_geometry\" + 0.017*\"n_hydrogen\" + 0.017*\"distort_tetrahedral_geometry\" + 0.016*\"weak_c_h\" + 0.016*\"asymmetric_unit\" + 0.015*\"asymmetric_unit_independent_molecule\" + 0.013*\"c_h\" + 0.013*\"n_atom\"\n",
      "\n",
      "Topic: 5 Word: 0.023*\"n_n_h\" + 0.019*\"bond_length\" + 0.018*\"c_h\" + 0.018*\"weak_c_h\" + 0.017*\"c_o\" + 0.016*\"c_o_h\" + 0.015*\"benzene_ring\" + 0.015*\"dihedral_angle\" + 0.014*\"intramolecular_hydrogen_bond\" + 0.013*\"n_interaction\"\n",
      "\n",
      "Topic: 6 Word: 0.027*\"neutron_diffraction\" + 0.025*\"high_resolution\" + 0.025*\"cl_atom\" + 0.023*\"experimental_datum\" + 0.018*\"electron_beam\" + 0.018*\"scatter_curve\" + 0.017*\"neutron_scatter\" + 0.016*\"o_h_pair\" + 0.016*\"small_angle\" + 0.013*\"terminal_phenyl_ring\"\n",
      "\n",
      "Topic: 7 Word: 0.024*\"sn_atom\" + 0.021*\"rotation_axis\" + 0.019*\"twofold_rotation_axis\" + 0.018*\"fuse_ring\" + 0.017*\"bond_angle\" + 0.017*\"rigid_body\" + 0.016*\"n_atom\" + 0.016*\"large_range\" + 0.015*\"stack_interaction\" + 0.015*\"metal_atom\"\n",
      "\n",
      "Topic: 8 Word: 0.023*\"c_h\" + 0.021*\"c_n_h\" + 0.019*\"cl_minus\" + 0.018*\"c_atom\" + 0.017*\"asymmetric_unit\" + 0.017*\"aring_deviation\" + 0.017*\"o_hydrogen_bond\" + 0.016*\"b_axis\" + 0.014*\"dihedral_angle\" + 0.013*\"phenyl_ring\"\n",
      "\n",
      "Topic: 9 Word: 0.061*\"space_group\" + 0.048*\"aring_resolution\" + 0.039*\"unit_cell\" + 0.029*\"unit_cell_parameter\" + 0.020*\"active_site\" + 0.020*\"c_terminal\" + 0.019*\"c_bond\" + 0.019*\"asymmetric_unit\" + 0.018*\"n_terminal\" + 0.017*\"vapour_diffusion\"\n",
      "\n",
      "Topic: 10 Word: 0.040*\"membered_ring\" + 0.036*\"small_angle\" + 0.035*\"envelope_conformation\" + 0.026*\"distribution_function\" + 0.025*\"x_ray_scatter\" + 0.024*\"x_ray\" + 0.023*\"chair_conformation\" + 0.018*\"half_chair\" + 0.018*\"real_space\" + 0.016*\"half_chair_conformation\"\n",
      "\n",
      "Topic: 11 Word: 0.034*\"x_ray\" + 0.028*\"s_hydrogen_bond\" + 0.025*\"scatter_intensity\" + 0.025*\"schiff_base_ligand\" + 0.023*\"x_ray_analysis\" + 0.022*\"intramolecular_o_h\" + 0.021*\"base_ligand\" + 0.019*\"s_hydrogen\" + 0.018*\"powder_diffraction\" + 0.018*\"lattice_parameter\"\n",
      "\n",
      "Topic: 12 Word: 0.031*\"dihedral_angle\" + 0.028*\"c_h\" + 0.025*\"intermolecular_c_h\" + 0.024*\"weak_intermolecular_c_h\" + 0.021*\"benzene_ring\" + 0.021*\"respectively_deg\" + 0.020*\"ring_system\" + 0.019*\"inversion_center\" + 0.016*\"phenyl_ring\" + 0.014*\"o_interaction\"\n",
      "\n",
      "Topic: 13 Word: 0.056*\"x_ray\" + 0.029*\"symmetry_centre\" + 0.024*\"weak_c_h\" + 0.018*\"intermolecular_hydrogen_bond\" + 0.015*\"o_interaction\" + 0.015*\"start_material\" + 0.014*\"weak_c\" + 0.013*\"anion_cation\" + 0.013*\"different_type\" + 0.013*\"c_alpha\"\n",
      "\n",
      "Topic: 14 Word: 0.026*\"c_torsion_angle\" + 0.022*\"intermolecular_interaction\" + 0.019*\"dihedral_angle_deg\" + 0.018*\"heterocyclic_ring\" + 0.018*\"square_plane\" + 0.015*\"absolute_configuration\" + 0.015*\"good_agreement\" + 0.015*\"mean_deviation\" + 0.014*\"membered_chelate_ring\" + 0.014*\"computer_simulation\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = 5\n",
    "passes = 20\n",
    "iterations = 500\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=topics, id2word=dictionary, passes=passes, workers =4)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run #1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-0d9eeb5d9ac2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mcorpus_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumTops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mcoherenceModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    238\u001b[0m                             ((force and queue_size[0] == 0) or\n\u001b[0;32m    239\u001b[0m                                  (self.eval_every != 0 and (self.num_updates / updateafter) % self.eval_every == 0)):\n\u001b[1;32m--> 240\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mchunk_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mperwordbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         logger.info(\n\u001b[0;32m    581\u001b[0m             \u001b[1;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bound: at document #%i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;31m# TODO treat zeros explicitly, instead of adding epsilon?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDTYPE_TO_EPS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m             \u001b[0mphinorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[1;31m# Iterate between gamma and phi until convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_topic_ratio = 0.005\n",
    "resistance = 0.7\n",
    "done = False\n",
    "numTops = 5\n",
    "\n",
    "topicPath = \"topics.csv\"\n",
    "relationPath = \"relations.csv\"\n",
    "\n",
    "topicFile = open(topicPath, 'w')\n",
    "topicOut =  csv.writer(topicFile, lineterminator = '\\n')\n",
    "topicOut.writerow([\"row\", \"run\", \"topic\", \"terms\", \"p\"])\n",
    "\n",
    "\n",
    "relationFile = open(relationPath, 'w')\n",
    "relationOut = csv.writer(relationFile, lineterminator = '\\n')\n",
    "relationOut.writerow([\"run\", \"topic\", \"IDs\", \"ID/strength\"])\n",
    "\n",
    "run = 1\n",
    "totalTopics = 0\n",
    "averageCoherence = 0\n",
    "badIDs = docIDs\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    print(\"run #\" + str(run))\n",
    "    \n",
    "    doc2topic = dict()\n",
    "    topic2doc = dict()\n",
    "    \n",
    "    \n",
    "    oldIDs = badIDs.copy()\n",
    "    badIDs = list()\n",
    "    \n",
    "    totalTopics += numTops\n",
    "    \n",
    "    #perform LDA\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=numTops, id2word=dictionary, passes=10, workers=4)\n",
    "    \n",
    "    coherenceModel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherenceModel.get_coherence()\n",
    "    averageCoherence = ((totalTopics-numTops) * averageCoherence + numTops*coherence)/totalTopics\n",
    "    \n",
    "    # tag documents\n",
    "    for ID in oldIDs:\n",
    "        \n",
    "        doc = docTokens[ID]\n",
    "        vec = dictionary.doc2bow(doc)\n",
    "\n",
    "        store = lda_model[vec]\n",
    "\n",
    "        bestRel = 0\n",
    "\n",
    "        # build relations\n",
    "        for pair in store:\n",
    "            \n",
    "            bestRel = max(bestRel, pair[1])\n",
    "\n",
    "            if pair[0] in topic2doc:\n",
    "                topic2doc[pair[0]] += [(ID, pair[1])]\n",
    "            else:\n",
    "                topic2doc[pair[0]] = [(ID, pair[1])]\n",
    "\n",
    "        # collect bad docs    \n",
    "        if bestRel < resistance:\n",
    "\n",
    "            badIDs.append(ID)\n",
    "    \n",
    "    \n",
    "    #write terms\n",
    "    \n",
    "    top_words_per_topic = []\n",
    "    for t in range(lda_model.num_topics):\n",
    "        top_words_per_topic.extend([(run, t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
    "\n",
    "        \n",
    "    terms = pd.DataFrame(top_words_per_topic, columns=['Run', 'Topic', 'Word', 'P']).to_csv(topicPath, mode='a', header=False)\n",
    "    \n",
    "    \n",
    "    # print relations\n",
    "    for topic in topic2doc:\n",
    "        relationOut.writerow([run, topic, len(topic2doc[topic])]+ sorted(topic2doc[topic], key=operator.itemgetter(1), reverse=True))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # done?\n",
    "    if len(badIDs) == 0:\n",
    "        done = True\n",
    "        print(\"Done!\")\n",
    "    \n",
    "    # if not, build new corpus\n",
    "    else:\n",
    "        print(len(badIDs))\n",
    "        corpus = [dictionary.doc2bow(docTokens[docID]) for docID in badIDs]\n",
    "        len(corpus)\n",
    "        numTops = math.ceil(len(badIDs) * id_topic_ratio)\n",
    "        run += 1\n",
    "\n",
    "        \n",
    "print(totalTopics)\n",
    "print(averageCoherence)\n",
    "\n",
    "topicFile.close()\n",
    "relationFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
