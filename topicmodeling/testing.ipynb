{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjz1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "import operator\n",
    "from operator import methodcaller\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import math\n",
    "import itertools\n",
    "import sqlite3\n",
    "import copy\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to blacklisted tokens\n",
    "blacklist = [t.strip() for t in next(csv.reader(open(\"tools\\\\blacklist.csv\", 'r')))]\n",
    "\n",
    "# levels of R&R terms considered\n",
    "levels = [1, 2, 3]\n",
    "\n",
    "# format [term, orig, sentence, docID]\n",
    "inPath = \"raw.csv\"\n",
    "inFile = open(inPath, 'r')\n",
    "inReader = csv.reader(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docTokens = dict()\n",
    "\n",
    "\n",
    "next(inReader)\n",
    "for inRow in inReader:\n",
    "    term = inRow[0]\n",
    "    sentence = inRow[2]\n",
    "    docID = inRow[3]\n",
    "    \n",
    "    token = \"_\".join([t for t in term.split(\":\") if re.match(r'[^\\W\\d]*$', t) and not t in blacklist])\n",
    "    \n",
    "    level = token.count(\"_\")\n",
    "    \n",
    "    if level in levels and not token in blacklist and len(token) > 0:\n",
    "        if docID in docTokens:\n",
    "            docTokens[docID] += [token]\n",
    "        else:\n",
    "            docTokens[docID] = [token]\n",
    "\n",
    "docIDs = list(docTokens.keys())\n",
    "data = list(docTokens.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16391\n",
      "1705\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(len(dictionary))\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=1, keep_n=15000)\n",
    "print(len(dictionary))\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4208800786237962\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=6, id2word=dictionary, passes=10, workers =4, iterations=500)\n",
    "\n",
    "coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "print(coherencemodel.get_coherence())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
